{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "path1 = \"/home/piotr/piotr/inz/indoor-semantic-segmentation/\"\n",
    "path2 = \"/mnt/c/Users/piotr.hondra/Documents/inz/indoor-semantic-segmentation/\"\n",
    "path3 = \"/Users/piotr/Documents/studia/indoor-semantic-segmentation/\"\n",
    "path = path3\n",
    "sys.path.append(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piotr/Documents/studia/indoor-semantic-segmentation/.venv/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/piotr/Documents/studia/indoor-semantic-segmentation/.venv/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: (__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE)\n",
      "  Referenced from: '/Users/piotr/Documents/studia/indoor-semantic-segmentation/.venv/lib/python3.9/site-packages/torchvision/image.so'\n",
      "  Expected in: '/Users/piotr/Documents/studia/indoor-semantic-segmentation/.venv/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from src import multitask_datamod, constants\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/piotr/Documents/studia/indoor-semantic-segmentation/datasets/train/rgb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dm \u001b[39m=\u001b[39m multitask_datamod\u001b[39m.\u001b[39mClassificationDataModule(path, transforms \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m dm\u001b[39m.\u001b[39;49msetup(\u001b[39m\"\u001b[39;49m\u001b[39mfit\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m train \u001b[39m=\u001b[39m dm\u001b[39m.\u001b[39mtrain_set\n",
      "File \u001b[0;32m~/Documents/studia/indoor-semantic-segmentation/src/multitask_datamod.py:50\u001b[0m, in \u001b[0;36mClassificationDataModule.setup\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup\u001b[39m(\u001b[39mself\u001b[39m, stage: \u001b[39mstr\u001b[39m):\n\u001b[1;32m     49\u001b[0m     data_class \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mNYUv2ClassificationDataset\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_set \u001b[39m=\u001b[39m data_class(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_dirs(\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m), transform\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransforms)\n\u001b[1;32m     52\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_set \u001b[39m=\u001b[39m data_class(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_dirs(\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m), transform\u001b[39m=\u001b[39mtransforms\u001b[39m.\u001b[39mt2)\n\u001b[1;32m     53\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_set \u001b[39m=\u001b[39m data_class(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_dirs(\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m), transform\u001b[39m=\u001b[39mtransforms\u001b[39m.\u001b[39mt2)\n",
      "File \u001b[0;32m~/Documents/studia/indoor-semantic-segmentation/src/dataset.py:56\u001b[0m, in \u001b[0;36mNYUv2ClassificationDataset.__init__\u001b[0;34m(self, image_dir, scene_dir, transform)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscene_ids \u001b[39m=\u001b[39m constants\u001b[39m.\u001b[39mSCENE_MERGED_IDS\n\u001b[1;32m     53\u001b[0m \u001b[39m# self.scene_ids = constants.SCENE_IDS\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39m# constants.SCENE_IDS[constants.SCENE_MERGED]\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimages \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(image_dir))\n\u001b[1;32m     57\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscenes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_scenes(scene_dir)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/piotr/Documents/studia/indoor-semantic-segmentation/datasets/train/rgb'"
     ]
    }
   ],
   "source": [
    "dm = multitask_datamod.ClassificationDataModule(path, transforms = None)\n",
    "dm.setup(\"fit\")\n",
    "train = dm.train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train[0][0]/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train[0][1], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants.MERGED_SCENES_IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "a = np.zeros((len(train),7))\n",
    "for idx, (img,mask) in tqdm(enumerate(train), total=len(train)):\n",
    "    indices, vals = np.unique(mask, return_counts=True)\n",
    "    # list(map(int,indices.tolist()))\n",
    "    indices.astype(int)\n",
    "    # indices[indices==255] = 40\n",
    "    indices = indices.astype(np.uint8)\n",
    "    a[idx,indices] = vals\n",
    "    # ap[]\n",
    "#     for idx in indices\n",
    "#     break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# columns = [str(i) for i in range(41)]\n",
    "# columns[40] = \"255\"\n",
    "df = pd.DataFrame(a, columns=constants.MERGED_SCENES_IDS.values())\n",
    "df.sum(axis=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "ax = sns.barplot(df.sum(axis=0).reset_index(), x=0, y=\"index\", color=\"green\", log=False)\n",
    "# for i in ax.containers:\n",
    "#     ax.bar_label(i,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04ad001dea4fb92ea081985347722387abdae6b7882ec73362cdd34f04c29939"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
